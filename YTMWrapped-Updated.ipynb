{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "FmltjvtB8aHZ",
        "aSOM1_jI8b8z",
        "yxkOzBYWZxea"
      ],
      "authorship_tag": "ABX9TyPde2HMWZKcxaQBnCbl6FS0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Todo\n",
        "ANALYSIS\n",
        "- longest listening session\n",
        "- PLAYLISTS (this will be a little tougher?)\n",
        "- GENRE ANALYSIS FUNCTIONS\n",
        "\n",
        "NEW FEATURES\n",
        "- matplotlib & GUI libraries (until more aesthetic things can be found) (**WIP**)\n",
        "- skip detection via timestamps of listen & duration of song\n",
        "- combine songs with identical titles and artists but different URLs (under the same URL - idfk). Create ID system instead of using URLs as identifiers).\n",
        "\t- maybe have a google photos \"is this the same person\" style prompt for these once a UI is created\n",
        "- databse that doesn't force you to ping API 4K times per analysis if you just want to add a couple songs\n",
        "- add musicbrainz (or another) API to get genre and decade and album and other really good song data (**WIP**)\n",
        "\n",
        "GENERAL USABILITY\n",
        "- make all calculations involving durations optional depending on the durations flag (from the YT api)\n",
        "\t- maybe even remove flags all together and just make a GUI because there are going to be so many options\n",
        "- this program is REALLY bad at accounting for everything\n",
        "  - from leap years\n",
        "  - to days not listened to music\n",
        "  - to if the user doesn't have the durations\n",
        "  - yeah im sure theres so much other stuff\n",
        "  - new features are EST-only friendly (timezone flag could fix?)\n",
        "- primitive documentation\n",
        "- fix flags system (mostly for debugging at this pt)\n",
        "- add stuff to the actual html report\n",
        "\n",
        "LONG TERM\n",
        "- understand songs' relation to one another by their sequence\n",
        "- music as NLP: each song is a word, each session a sentence\n",
        "\t- start by BoW model using song IDs"
      ],
      "metadata": {
        "id": "RXRnkI-DXCJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import sys\n",
        "import getopt\n",
        "import json\n",
        "import requests\n",
        "import re\n",
        "import pandas as pd\n",
        "import collections\n",
        "import os\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import pytz\n",
        "import itertools\n",
        "import numpy as np\n",
        "import urllib.parse\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from IPython.display import HTML, display\n",
        "import time\n",
        "import ast"
      ],
      "metadata": {
        "id": "ge083-6rStL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "ptEQU3aVJZFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loader class"
      ],
      "metadata": {
        "id": "iq7_lIIX8Xe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Loader():\n",
        "    # backbone methods\n",
        "    def __init__(self, duration, more_details, use_songs, analyze_year, apikey, filepath, ignores={\"Title\": [], \"Artist\": [], \"URL\": []}):\n",
        "        self.duration, self.more_details, self.use_songs, self.analyze_year, self.apikey, self.filepath, self.ignores = (duration, more_details, use_songs, analyze_year, apikey, filepath, ignores)\n",
        "        self.file = self.open_file(self.filepath, \".json\")\n",
        "        self.out = display(self.progress(0, 100), display_id=True)\n",
        "\n",
        "    # utility methods\n",
        "    def should_not_ignore(self, title, year, header):\n",
        "        if (header == \"YouTube Music\" and title[:7] == \"Watched\" and year[:4] in self.analyze_year):\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def open_file(self, filepath, filetype):\n",
        "        if (filepath.endswith(filetype)):\n",
        "            try:\n",
        "                file = open(filepath, \"r\", encoding=\"utf8\")\n",
        "                return file\n",
        "            except:\n",
        "                print(\"Could not open your report file\")\n",
        "                sys.exit()\n",
        "        else:\n",
        "            print(\"There was an error opening your report files.\")\n",
        "            sys.exit()\n",
        "\n",
        "\n",
        "    # processes bulk lists\n",
        "    def parse_json(self):\n",
        "        self.history = {\"Title\": [], \"Artist\": [], \"Year\": [], \"URL\": [], \"Duration\": []}\n",
        "        json_object = json.load(self.file)\n",
        "        for obj in json_object:\n",
        "            if (self.should_not_ignore(obj['title'], obj['time'], obj['header'])):\n",
        "                if ('subtitles' in obj):\n",
        "                    self.history[\"Title\"].append(obj['title'][8:])\n",
        "                    self.history[\"Artist\"].append(obj['subtitles'][0]['name'].replace('- Topic ', '').replace('- Topic', ''))\n",
        "                    self.history[\"Year\"].append(obj['time'])\n",
        "                    self.history[\"URL\"].append(obj['titleUrl'][32:])\n",
        "                    self.history[\"Duration\"].append(0)\n",
        "\n",
        "        # preprocessing\n",
        "        for i in range(len(self.history[\"Title\"])):\n",
        "            if i >= len(self.history[\"Title\"]):\n",
        "                break\n",
        "            if self.history[\"Title\"][i] in self.ignores[\"Title\"] or self.history[\"Artist\"][i] in self.ignores[\"Artist\"] or self.history[\"URL\"][i] in self.ignores[\"URL\"]:\n",
        "                del self.history[\"Title\"][i]\n",
        "                del self.history[\"Artist\"][i]\n",
        "                del self.history[\"Year\"][i]\n",
        "                del self.history[\"URL\"][i]\n",
        "                del self.history[\"Duration\"][i]\n",
        "                i-= 1\n",
        "\n",
        "        occurrences = collections.Counter(self.history['URL'])\n",
        "        self.history['Occurrences'] = []\n",
        "        for i in self.history['URL']:\n",
        "            self.history['Occurrences'].append(occurrences[i])\n",
        "\n",
        "        occurrences = collections.Counter(self.history['Artist'])\n",
        "        duration = [0]*len(occurrences.keys())\n",
        "        self.artists = {\"Artist\": occurrences.keys(), \"Occurrences\": occurrences.values(), \"Duration\": duration}\n",
        "\n",
        "    # generates dataframes and csv files\n",
        "    def gen_csvs(self, genfolder=True):\n",
        "        if genfolder:\n",
        "            os.chdir(\"generated-reports\") # may be volatile\n",
        "            datestring = \"-\" + str(datetime.datetime.now().strftime(\"%d.%m.%Y-%H.%M.%S\"))\n",
        "            os.mkdir(datestring[1:])\n",
        "            os.chdir(datestring[1:])\n",
        "        else:\n",
        "            datestring = \"\"\n",
        "\n",
        "        self.historyDF = pd.DataFrame(self.history)\n",
        "        self.historyDF.to_csv(\"report-history.csv\")\n",
        "\n",
        "        self.artistsDF = pd.DataFrame(self.artists)\n",
        "        self.artistsDF.to_csv(\"report-artists.csv\")\n",
        "\n",
        "        self.songsDF = pd.DataFrame(self.history)\n",
        "        self.total_songs = len(self.songsDF)\n",
        "        # TODO more comprehensive duplicate dropping function (much further down the line)\n",
        "        self.songsDF.drop_duplicates(subset=['URL'], inplace=True)\n",
        "        self.unique_songs = len(self.songsDF)\n",
        "        self.songsDF = self.songsDF.reset_index(drop=True)\n",
        "        self.songsDF.to_csv(\"report-songs.csv\")\n",
        "\n",
        "        if genfolder:\n",
        "            os.chdir(\"../../\")\n",
        "\n",
        "    # API management functions\n",
        "    def parse_duration(self, duration):\n",
        "        timestr = duration\n",
        "        time = re.findall(r'\\d+', timestr)\n",
        "        length = len(time)\n",
        "        if length > 4:\n",
        "            return 0\n",
        "        if length == 4:\n",
        "            return ((int(time[0])*24*60*60)+(int(time[1])*60*60)+int(time[2]*60)+(int(time[3])))\n",
        "        elif length == 3:\n",
        "            return ((int(time[0])*60*60)+(int(time[1])*60)+(int(time[2])))\n",
        "        elif length == 2:\n",
        "            return ((int(time[0])*60)+(int(time[1])))\n",
        "        elif length == 1:\n",
        "            return (int(time[0]))\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def call_api(self, idlist):\n",
        "        parameters = {\"part\": \"contentDetails,snippet\",\n",
        "                      \"id\": ','.join(idlist), \"key\": self.apikey}\n",
        "        response = requests.get(\n",
        "            \"https://www.googleapis.com/youtube/v3/videos\", params=parameters)\n",
        "\n",
        "        if (response.status_code == 200):\n",
        "            json_parsed = response.json()\n",
        "            for item in json_parsed['items']:\n",
        "                duration = self.parse_duration(item['contentDetails']['duration'])\n",
        "                url = item['id']\n",
        "                if duration < 10:\n",
        "                    duration = duration * 60\n",
        "\n",
        "                # update by url\n",
        "                for (j, i) in enumerate(self.history[\"URL\"]):\n",
        "                    if i == url:\n",
        "                        if duration >= 10:\n",
        "                            self.history[\"Duration\"][j] = duration\n",
        "\n",
        "    def progress(self, value, max=100):\n",
        "        return HTML(\"\"\"\n",
        "            <progress\n",
        "                value='{value}'\n",
        "                max='{max}',\n",
        "                style='width: 100%'\n",
        "            >\n",
        "                {value}\n",
        "            </progress>\n",
        "        \"\"\".format(value=value, max=max))\n",
        "\n",
        "    def get_duration(self):\n",
        "        # Count duration\n",
        "        idlist = []\n",
        "        calls = 0\n",
        "        unique_song_urls = set(self.history['URL'])\n",
        "        len_usurl = len(unique_song_urls)\n",
        "        print(\"Getting durations. This may take a while. Awaiting\", len_usurl, \"requests.\")\n",
        "        for url in unique_song_urls:\n",
        "            idlist.append(url)\n",
        "            if len(idlist) == 50:\n",
        "                # print(\"\\tGetting info on videos \" + str(1+50*calls) + \" - \" + str(50+50*calls)) # uglier GUI\n",
        "                self.out.update(self.progress(((1+50*calls)*100)/len_usurl, 100))\n",
        "                self.call_api(idlist)\n",
        "                calls += 1\n",
        "                idlist = []\n",
        "        # print(\"\\tGetting info on videos \" + str(1+50*calls) + \" - \" + str(len(unique_song_urls))) # uglier GUI\n",
        "        self.out.update(self.progress(100, 100))\n",
        "        self.call_api(idlist)\n",
        "\n",
        "        # update artist durations\n",
        "        # i know this section is garbage i'll make it nicer later\n",
        "        artist_durations = {}\n",
        "        for i in range(len(self.history[\"Artist\"])):\n",
        "            duration = self.history[\"Duration\"][i]\n",
        "            artist = self.history[\"Artist\"][i]\n",
        "            try:\n",
        "                artist_durations[artist] += duration\n",
        "            except:\n",
        "                artist_durations[artist] = duration\n",
        "\n",
        "        occurrences = collections.Counter(self.history[\"Artist\"])\n",
        "        artists_dict = collections.defaultdict(list)\n",
        "        for i in (artist_durations, occurrences):\n",
        "            for key, val in i.items():\n",
        "                artists_dict[key].append(val)\n",
        "\n",
        "        durations = []\n",
        "        occurrences = []\n",
        "        for i, j in artists_dict.values():\n",
        "            durations.append(i)\n",
        "            occurrences.append(j)\n",
        "\n",
        "        self.artists = {\"Artist\": artists_dict.keys(), \"Occurrences\": occurrences, \"Duration\": durations}\n",
        "\n",
        "        self.gen_csvs()\n",
        "\n",
        "    def outs(self):\n",
        "        print(\"We are now processing your file\")\n",
        "        self.parse_json()\n",
        "\n",
        "        if self.duration:\n",
        "            self.get_duration()\n",
        "        else:\n",
        "            self.gen_csvs() # generates dataframes and CSVs\n",
        "\n",
        "        return self.historyDF, self.artistsDF, self.songsDF\n",
        "\n",
        "    def load(self, loadfp):\n",
        "        print(\"Loading your preprocessed history files\")\n",
        "        historyDF = pd.read_csv(self.open_file(os.path.join(loadfp, \"report-history.csv\"), \".csv\"))\n",
        "        artistsDF = pd.read_csv(self.open_file(os.path.join(loadfp, \"report-artists.csv\"), \".csv\"))\n",
        "        songsDF = pd.read_csv(self.open_file(os.path.join(loadfp, \"report-songs.csv\"), \".csv\"))\n",
        "        return historyDF, artistsDF, songsDF"
      ],
      "metadata": {
        "id": "_MN-ZLgfjMBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyzer class"
      ],
      "metadata": {
        "id": "FmltjvtB8aHZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vyqw36-9So1d"
      },
      "outputs": [],
      "source": [
        "class Analyzer():\n",
        "    def __init__(self, historyDF, artistsDF, songsDF):\n",
        "        self.history = historyDF\n",
        "        self.artists = artistsDF\n",
        "        self.songs = songsDF\n",
        "\n",
        "    def tops(self):\n",
        "        # Top 10 Songs\n",
        "        songs_top = self.songs.nlargest(10, ['Occurrences'])\n",
        "\n",
        "        # Top 10 Artists\n",
        "        artists_top = self.artists.nlargest(10, ['Duration'])\n",
        "\n",
        "        return artists_top, songs_top\n",
        "\n",
        "    def meta(self):\n",
        "        meta = {}\n",
        "        meta[\"Total Seconds\"] = sum(self.history[\"Duration\"])\n",
        "        meta[\"Total Songs\"] = len(self.history[\"Title\"])\n",
        "        meta[\"Unique Songs\"] = len(self.songs[\"Title\"])\n",
        "        meta[\"Unique Artists\"] = len(self.artists[\"Artist\"])\n",
        "        return meta\n",
        "\n",
        "    # specific optional analysis functions\n",
        "    def uniques(self):\n",
        "        uniques = {}\n",
        "        uniques[\"Top 10 Unique Artists\"] = collections.Counter(self.songs[\"Artist\"]).most_common(10)\n",
        "        return uniques\n",
        "\n",
        "    def repeats(self):\n",
        "        repeats = {}\n",
        "        grouped_history = [(_, sum(1 for ii in i)) for _,i in itertools.groupby(self.history[\"URL\"])]\n",
        "        grouped_history.sort(key = lambda x : x[1])\n",
        "        grouped_history.reverse()\n",
        "        repeats[\"Most Consecutively Repeated Song\"] = grouped_history[:10]\n",
        "        repeats[\"Sweet 16\"] = self.songs.nlargest(16, [\"Occurrences\"])\n",
        "        repeats[\"Sweet 16 Artists Occurrences\"] = self.artists.nlargest(16, [\"Occurrences\"])\n",
        "        repeats[\"Sweet 16 Artists Durations\"] = self.artists.nlargest(16, [\"Duration\"])\n",
        "\n",
        "        return repeats\n",
        "\n",
        "    def chronology(self, n=3):\n",
        "        # this stuff will break if you are analyzing a period longer than a year\n",
        "\n",
        "        chronology = {}\n",
        "        top_songs_per_month = []\n",
        "        for month in range(12):\n",
        "            songs_for_month = {\"Title\": [], \"Artist\": [], \"URL\": [], \"Duration\": []}\n",
        "            for j,i in enumerate(self.history[\"Year\"]):\n",
        "                if int(i[5:7]) == month+1:\n",
        "                    songs_for_month[\"Title\"].append(self.history[\"Title\"][j])\n",
        "                    songs_for_month[\"Artist\"].append(self.history[\"Artist\"][j])\n",
        "                    songs_for_month[\"URL\"].append(self.history[\"URL\"][j])\n",
        "                    songs_for_month[\"Duration\"].append(self.history[\"Duration\"][j])\n",
        "\n",
        "            occurrences = collections.Counter(songs_for_month['URL'])\n",
        "            songs_for_month['Occurrences'] = []\n",
        "            for i in songs_for_month['URL']:\n",
        "                songs_for_month['Occurrences'].append(occurrences[i])\n",
        "            songs_for_month_DF = pd.DataFrame(songs_for_month)\n",
        "            songs_for_month_DF.drop_duplicates(subset=['URL'], inplace=True)\n",
        "            top_songs_per_month.append(songs_for_month_DF.nlargest(n, ['Occurrences']))\n",
        "\n",
        "        chronology[\"Top n Songs Per Month\"] = top_songs_per_month\n",
        "\n",
        "        days = {}\n",
        "        for j, i in enumerate(self.history[\"Year\"]):\n",
        "            try:\n",
        "                days[i[5:10]][\"Title\"].append(self.history[\"Title\"][j])\n",
        "                days[i[5:10]][\"Artist\"].append(self.history[\"Artist\"][j])\n",
        "                days[i[5:10]][\"URL\"].append(self.history[\"URL\"][j])\n",
        "                days[i[5:10]][\"Duration\"].append(self.history[\"Duration\"][j])\n",
        "            except:\n",
        "                songs_for_day = {\"Title\": [self.history[\"Title\"][j]], \"Artist\": [self.history[\"Artist\"][j]], \"URL\": [self.history[\"URL\"][j]], \"Duration\": [self.history[\"Duration\"][j]]}\n",
        "                days[i[5:10]] = songs_for_day\n",
        "\n",
        "        \"\"\"\n",
        "        # TEMPORARILY BLOCKED BECAUSE ITS SUPER BROKEN\n",
        "\n",
        "        day_most_listened = -1 # day you listened to the most music function\n",
        "        durations_per_day = [] # durations per day function\n",
        "        songs_listened_dml = -1\n",
        "        for j, i in enumerate(days.values()):\n",
        "            urls = collections.Counter(i[\"URL\"])\n",
        "            if ((len(urls.values())) > songs_listened_dml):\n",
        "                day_most_listened = j\n",
        "                songs_listened_dml = len(urls.values())\n",
        "            durations_per_day.append(sum(i[\"Duration\"]))\n",
        "\n",
        "        # since it counts from NOW to the past, this is in reverse order (this breaks of day 1 of the dataset isn't jan 1... uh oh)\n",
        "        chronology[\"Most Diverse Day\"] = [len(days) - day_most_listened , durations_per_day[day_most_listened]//60, songs_listened_dml] # this is the Nth day of the year\n",
        "        chronology[\"Durations Per Day\"] = durations_per_day\n",
        "        chronology[\"Most Musical Day\"] = [len(days) - durations_per_day.index(max(durations_per_day)), max(durations_per_day)//60]\n",
        "        \"\"\"\n",
        "\n",
        "        times = {}\n",
        "        localtime = pytz.timezone(\"US/Eastern\")\n",
        "        hrs = [i for i in range(0, 24)]\n",
        "        errs = 0\n",
        "        chronology[\"Songs Per Time of Day\"] = dict()\n",
        "        for i in range(24):\n",
        "            chronology[\"Songs Per Time of Day\"][i] = 0\n",
        "        for i in self.history[\"Year\"]:\n",
        "            try:\n",
        "                isDST = bool(localtime.localize(datetime.datetime.strptime(i[:-5], \"%Y-%m-%dT%H:%M:%S\")).dst())\n",
        "                x = int(i[11:13])\n",
        "                if isDST:\n",
        "                    x += 1\n",
        "                x -= 5\n",
        "                x = hrs[x]\n",
        "                try:\n",
        "                    times[x] += 1\n",
        "                except:\n",
        "                    times[x] = 1\n",
        "            except:\n",
        "                errs += 1\n",
        "\n",
        "        for i, j in times.items():\n",
        "            chronology[\"Songs Per Time of Day\"][i] = j\n",
        "        chronology[\"Songs Per Time of Day Errors\"] = errs\n",
        "\n",
        "        weekdays = {}\n",
        "        errs = 0\n",
        "        for i in self.history[\"Year\"]:\n",
        "            try:\n",
        "                wd = datetime.datetime.strptime(i[:-5], \"%Y-%m-%dT%H:%M:%S\").weekday()\n",
        "                try:\n",
        "                    weekdays[wd] += 1\n",
        "                except:\n",
        "                    weekdays[wd] = 1\n",
        "            except:\n",
        "                errs += 1\n",
        "\n",
        "        chronology[\"Days of the Week\"] = weekdays\n",
        "        chronology[\"Days of the Week Errors\"] = errs\n",
        "\n",
        "        # this code can technically be inserted earlier when we process months\n",
        "        months = {}\n",
        "        for i in self.history[\"Year\"]:\n",
        "            try:\n",
        "                months[int(i[5:7])] += 1\n",
        "            except:\n",
        "                months[int(i[5:7])] = 1\n",
        "\n",
        "        chronology[\"Songs Per Month\"] = months\n",
        "\n",
        "        return chronology\n",
        "\n",
        "    def averages(self):\n",
        "        averages = {}\n",
        "        averages[\"Average Song Length\"] = sum(self.history[\"Duration\"]) / len(self.history[\"Duration\"])\n",
        "        averages[\"Average Song Length Unique\"] = sum(self.songs[\"Duration\"]) / len(self.songs[\"Duration\"])\n",
        "        years = []\n",
        "        for i in self.history[\"Year\"]:\n",
        "            years.append(i[5:10])\n",
        "        averages[\"Average Seconds per Day\"] = sum(self.history[\"Duration\"]) / len(collections.Counter(years))\n",
        "\n",
        "        min_song_length = min(self.songs[\"Duration\"])\n",
        "        max_song_length = max(self.songs[\"Duration\"])\n",
        "        min_song_idx = list(self.songs[\"Duration\"]).index(min_song_length)\n",
        "        max_song_idx = list(self.songs[\"Duration\"]).index(max_song_length)\n",
        "\n",
        "        averages[\"Shortest Song\"] = [min_song_length, self.songs[\"Title\"][min_song_idx], self.songs[\"Artist\"][min_song_idx]]\n",
        "        averages[\"Longest Song\"] = [max_song_idx, self.songs[\"Title\"][max_song_idx], self.songs[\"Artist\"][max_song_idx]]\n",
        "\n",
        "        # 5th percentile song by duration?\n",
        "        # 95th percentile song by duration?\n",
        "        # median song length\n",
        "\n",
        "        history_duration_sorted = self.history[\"Duration\"].copy()\n",
        "        songs_duration_sorted = self.songs[\"Duration\"].copy()\n",
        "        history_duration_sorted = list(history_duration_sorted)\n",
        "        songs_duration_sorted = list(songs_duration_sorted)\n",
        "        history_duration_sorted.sort()\n",
        "        songs_duration_sorted.sort()\n",
        "        averages[\"Median Song Length\"] = history_duration_sorted[int(len(history_duration_sorted)/2)]\n",
        "        averages[\"Median Song Length Unique\"] = songs_duration_sorted[int(len(songs_duration_sorted)/2)]\n",
        "\n",
        "        #plt.hist(list(self.songs[\"Duration\"]), 30, (0, 600))\n",
        "        #plt.show()\n",
        "\n",
        "        averages[\"Average Replays\"] = sum(self.songs[\"Occurrences\"]) / len(self.songs[\"Occurrences\"])\n",
        "        averages[\"Max Replays\"] = max(self.songs[\"Occurrences\"]) # yes this statistic is already calculated somewhere else\n",
        "\n",
        "        frqtable = collections.Counter(self.songs[\"Occurrences\"])\n",
        "\n",
        "        averages[\"Occurrences Frequency Table\"] = frqtable\n",
        "\n",
        "        return averages\n",
        "\n",
        "    def genres(self):\n",
        "        # genre stuff!\n",
        "        allowed_vals_f = open('genres.txt', 'r')\n",
        "        allowed_vals = []\n",
        "        for i in allowed_vals_f:\n",
        "            allowed_vals.append(i.replace(\"\\n\", \"\"))\n",
        "\n",
        "        artist_tags = {}\n",
        "        print(len(self.artists['Artist']), \"Artists\")\n",
        "        for c, i in enumerate(self.artists['Artist']):\n",
        "            artist_tags[i] = []\n",
        "            response = requests.get(\"https://musicbrainz.org/ws/2/artist/?fmt=json&query=name:\" + urllib.parse.quote(i.strip()))\n",
        "            if c % 20 == 0:\n",
        "                print(\"Got\", c, \"artists\")\n",
        "            try:\n",
        "                tags = response.json()['artists'][0]['tags']\n",
        "                #print(tags)\n",
        "                for ii in tags:\n",
        "                    if ii['name'] in allowed_vals:\n",
        "                        for iii in range(ii['count']):\n",
        "                            artist_tags[i].append(ii['name'])\n",
        "            except:\n",
        "                #print(\"No tags for artist: \" + i)\n",
        "                pass\n",
        "\n",
        "    def sessions(self):\n",
        "        # split history into sessions (need to decide what distinguishes 1 session from another, most likely 30mins)\n",
        "        # get longest session as a statistic\n",
        "        # use sessions as \"sentences\" for starting to model music listening\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Formatter class"
      ],
      "metadata": {
        "id": "aSOM1_jI8b8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Formatter():\n",
        "    def gen_report(self, args, meta, artists_top, songs_top):\n",
        "\n",
        "        analyze_year, duration, more_details = args\n",
        "        total_seconds = meta[\"Total Seconds\"]\n",
        "\n",
        "        # TODO rewrite HTML report generation\n",
        "        # TODO Calculate total duration\n",
        "        htmlreport = open('report.html', 'w', encoding=(\"utf8\"))\n",
        "        print(\"\"\"<!DOCTYPE html><html><head><title>Wrapped</title><style type=\"text/css\">body{background-color: #000000;}.center-div{position: absolute; margin: auto; top: 0; right: 0; bottom: 0; left: 0; width: 50%; height: 90%; background-color: #000000; border-radius: 3px; padding: 10px;}.ytm_logo{width: 15%;position: relative;top: 30px;left: 40px;}.title_logo{width: 30%;position: relative;top: 30px;left: 60px;}.right_title{position: absolute;font-family: \"Product Sans\";top: 55px;right: 10%;font-size: 2em;color: #ffffff;}.container{position: relative;top: 13%;left: 53px;}.minutes_title{font-family: \"Product Sans\";font-size: 2em;color: #ffffff;}.minutes{font-family: \"Product Sans\";font-size: 6em;color: #ffffff;}.row{display: flex;}.column{flex: 50%;}.list{font-family: \"Roboto\";font-size: 1.5em;line-height: 30px;color: #ffffff;}</style></head><body><div class=\"center-div\"><img src=\"ytm_logo.png\" class=\"ytm_logo\"><img src=\"title.png\" class=\"title_logo\"/><span class=\"right_title\">\"\"\", file=htmlreport)\n",
        "        print(str(analyze_year), file=htmlreport)\n",
        "        print(\"\"\" Wrapped</span><div class=\"container\"><div class=\"minutes_title\">Minutes Listened</div><div class=\"minutes\">\"\"\", file=htmlreport)\n",
        "        if duration:\n",
        "            print(str(total_seconds//60), file=htmlreport)\n",
        "        else:\n",
        "            print(\"N/A\", file=htmlreport)\n",
        "        print(\"\"\"</div><br><br><div class=\"row\"><div class=\"column\"><div class=\"minutes_title\">Top Artists</div><div class=\"list\">\"\"\", file=htmlreport)\n",
        "\n",
        "        for i, j, v in zip(artists_top[\"Artist\"], artists_top[\"Occurrences\"], artists_top[\"Duration\"]): # TODO add durations to artist stuff\n",
        "            print(\"<br>\", file=htmlreport)\n",
        "            if more_details:\n",
        "                if duration:\n",
        "                    print('{0} - {1} songs ({2} mins)'.format(str(i), j, str(v//60)), file=htmlreport) # TODO v should be artist duration (?)\n",
        "                    pass\n",
        "                else:\n",
        "                    print('{0} - {1} songs'.format(str(i), j), file=htmlreport)\n",
        "            else:\n",
        "                print('{0}'.format(i), file=htmlreport)\n",
        "        print(\"\"\"</div></div><div class=\"column\"><div class=\"minutes_title\">Top Songs</div><div class=\"list\">\"\"\", file=htmlreport)\n",
        "        top_songs, top_artists, top_occurrences = songs_top['Title'], songs_top['Artist'], songs_top['Occurrences']\n",
        "        for i, j, k in zip(top_songs, top_artists, top_occurrences):\n",
        "            print(\"<br>\", file=htmlreport)\n",
        "            if more_details:\n",
        "                print('{0} - {1} - {2} plays'.format(j, i, k), file=htmlreport)\n",
        "            else:\n",
        "                print('{0} - {1}'.format(j, i), file=htmlreport)\n",
        "        print(\"\"\"</div></div></div></div></div></body></html>\"\"\", file=htmlreport)\n",
        "        htmlreport.close()"
      ],
      "metadata": {
        "id": "MzmkvU7QjQjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execution code"
      ],
      "metadata": {
        "id": "WgMjJSI48dMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"drive/My Drive/Colab Notebooks/ytmwrapped\")"
      ],
      "metadata": {
        "id": "f_G-o8b3Q839"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# flags\n",
        "# TODO fix parameter/flags system\n",
        "more_details, duration, analyze_year, use_songs, apikey, load, loadfp = (True, True, [\"2023\"], True, None, True, os.getcwd()+\"/generated-reports/21.08.2023-22.31.09\")\n",
        "token = open(\"apitoken.txt\", \"r\").read()\n",
        "apikey = token\n",
        "\n",
        "ignore = {}\n",
        "ignore[\"Title\"] = open(\"ignore-title.txt\", \"r\").read().split(\",\")\n",
        "ignore[\"Artist\"] = open(\"ignore-artist.txt\", \"r\").read().split(\",\")\n",
        "ignore[\"URL\"] = open(\"ignore-url.txt\", \"r\").read().split(\",\")\n",
        "# filepath = sys.argv[1]\n",
        "filepath = \"watch-history.json\"\n",
        "loader = Loader(duration, more_details, use_songs, analyze_year, apikey, filepath, ignores=ignore)\n",
        "if load:\n",
        "    history, artists, songs = loader.load(loadfp)\n",
        "else:\n",
        "    history, artists, songs = loader.outs()\n",
        "\n",
        "print()\n",
        "print(history.head())\n",
        "print()\n",
        "\n",
        "analyzer = Analyzer(history, artists, songs)\n",
        "artists_top, songs_top = analyzer.tops()\n",
        "meta = analyzer.meta()\n",
        "\n",
        "# TODO update formatter filesave system DO BEFORE UNCHECKING\n",
        "#formatter = Formatter()\n",
        "#formatter.gen_report((analyze_year, duration, more_details), meta, artists_top, songs_top)\n",
        "\n",
        "print(\" -- ANALYSIS DEBUGGING -- \")\n",
        "print(\" - Meta - \")\n",
        "print(analyzer.meta())\n",
        "print(\" - Uniques - \")\n",
        "print(analyzer.uniques())\n",
        "print(\" - Repeats - \")\n",
        "#print(analyzer.repeats())\n",
        "print(\" - Chronology - \")\n",
        "chrono = analyzer.chronology(n=5)\n",
        "for j, i in enumerate(chrono[\"Top n Songs Per Month\"]):\n",
        "    print(j)\n",
        "    print(i)\n",
        "    pass\n",
        "print(list(chrono.items())[1])\n",
        "print(list(chrono.items())[3])\n",
        "print(\" - Averages - \")\n",
        "averages = analyzer.averages()\n",
        "print(averages)\n",
        "\n",
        "print(\"All done!\")"
      ],
      "metadata": {
        "id": "HffdIbELSzka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# songs per times of the day\n",
        "# parts of this code needs credit\n",
        "\n",
        "times = chrono[\"Songs Per Time of Day\"]\n",
        "x = sorted(times.keys())\n",
        "y = []\n",
        "for i in x:\n",
        "    y.append(times[i])\n",
        "\n",
        "x = list(reversed(x))\n",
        "y = list(reversed(y))\n",
        "\n",
        "def rightRotate(lists, num):\n",
        "    output_list = []\n",
        "\n",
        "    for item in range(len(lists) - num, len(lists)):\n",
        "        output_list.append(lists[item])\n",
        "\n",
        "    for item in range(0, len(lists) - num):\n",
        "        output_list.append(lists[item])\n",
        "\n",
        "    return output_list\n",
        "\n",
        "x = rightRotate(x, 6)\n",
        "y = rightRotate(y, 6)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "ax = plt.subplot(111, polar=True)\n",
        "plt.axis('off')\n",
        "\n",
        "upperLimit = max(y)\n",
        "lowerLimit = min(y)\n",
        "\n",
        "maxval = max(y)\n",
        "\n",
        "slope = (maxval - lowerLimit) / maxval\n",
        "heights = [slope * i + lowerLimit for i in y]\n",
        "\n",
        "width = 2*np.pi / 24\n",
        "\n",
        "indexes = list(range(1, 25))\n",
        "angles = [element * width for element in indexes]\n",
        "\n",
        "grey_heights = [slope*maxval + lowerLimit] * 24\n",
        "\n",
        "# Draw bars\n",
        "bars = ax.bar(\n",
        "    x=angles,\n",
        "    height=grey_heights,\n",
        "    width=width,\n",
        "    bottom=lowerLimit,\n",
        "    linewidth=2,\n",
        "    edgecolor=\"white\",\n",
        "    color=\"#d3d3d3\",\n",
        ")\n",
        "\n",
        "bars = ax.bar(\n",
        "    x=angles,\n",
        "    height=heights,\n",
        "    width=width,\n",
        "    bottom=lowerLimit,\n",
        "    linewidth=2,\n",
        "    edgecolor=\"white\",\n",
        "    color=\"#61a4b2\",\n",
        ")\n",
        "\n",
        "labelPadding = 5\n",
        "\n",
        "for bar, angle, height, label in zip(bars,angles, heights, [str(i) for i in x]):\n",
        "\n",
        "    rotation = np.rad2deg(angle)\n",
        "\n",
        "    alignment = \"\"\n",
        "    if angle >= np.pi/2 and angle < 3*np.pi/2:\n",
        "        alignment = \"right\"\n",
        "        rotation = rotation + 180\n",
        "    else:\n",
        "        alignment = \"left\"\n",
        "\n",
        "    if (height > 100):\n",
        "        ax.text(\n",
        "            x=angle,\n",
        "            y=lowerLimit + height + labelPadding,\n",
        "            s=label,\n",
        "            ha=alignment,\n",
        "            va='center',\n",
        "            rotation=rotation,\n",
        "            rotation_mode=\"anchor\")"
      ],
      "metadata": {
        "id": "Ad--FGUdjKg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# listens per day of the week\n",
        "weekdays = [\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\"]\n",
        "plt.bar(weekdays, chrono[\"Days of the Week\"].values())\n",
        "print(chrono[\"Days of the Week Errors\"])"
      ],
      "metadata": {
        "id": "r69b6bzJiWZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# listens per month\n",
        "plt.bar(chrono[\"Songs Per Month\"].keys(), chrono[\"Songs Per Month\"].values())"
      ],
      "metadata": {
        "id": "4znkRaF-74qJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(averages['Occurrences Frequency Table'].keys(), averages['Occurrences Frequency Table'].values())\n",
        "plt.yscale(\"linear\") # \"log\""
      ],
      "metadata": {
        "id": "dCn-UcuK73_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "yF52K6t1SNH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MusicBrainz API"
      ],
      "metadata": {
        "id": "yxkOzBYWZxea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Genres"
      ],
      "metadata": {
        "id": "tRGcRBc28Zpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "allowed_vals_f = open('genres.txt', 'r')\n",
        "allowed_vals = []\n",
        "for i in allowed_vals_f:\n",
        "    allowed_vals.append(i.replace(\"\\n\", \"\"))"
      ],
      "metadata": {
        "id": "_dUJP3gJi_1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "artist_tags = {}\n",
        "print(len(artists['Artist']), \"Artists\")\n",
        "for c, i in enumerate(artists['Artist']):\n",
        "    artist_tags[i] = []\n",
        "    response = requests.get(\"https://musicbrainz.org/ws/2/artist/?fmt=json&query=name:\" + urllib.parse.quote(i.strip()))\n",
        "    if c % 20 == 0:\n",
        "        print(\"Got\", c, \"artists\")\n",
        "    try:\n",
        "        tags = response.json()['artists'][0]['tags']\n",
        "        #print(tags)\n",
        "        for ii in tags:\n",
        "            if ii['name'] in allowed_vals:\n",
        "                artist_tags[i].append(ii['name'])\n",
        "    except:\n",
        "        #print(\"No tags for artist: \" + i)\n",
        "        pass"
      ],
      "metadata": {
        "id": "P3ahcMQZZzfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alltags = itertools.chain(*artist_tags.values())\n",
        "counter = collections.Counter(alltags).most_common(10)\n",
        "genres = []\n",
        "counts = []\n",
        "for (i, j) in counter:\n",
        "    genres.append(i)\n",
        "    counts.append(j)\n",
        "plt.pie(counts, labels=genres, autopct=\"%1.1f%%\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XcrJBOmFm4JO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alltags = []\n",
        "artist_tags = tags2\n",
        "for i in history['Artist']:\n",
        "    if isinstance(artist_tags[i], str):\n",
        "        alltags.append(artist_tags[i])\n",
        "    else:\n",
        "        for ii in artist_tags[i]:\n",
        "            alltags.append(ii)\n",
        "counter = collections.Counter(alltags).most_common(10)\n",
        "genres = []\n",
        "counts = []\n",
        "for (i, j) in counter:\n",
        "    genres.append(i)\n",
        "    counts.append(j)\n",
        "plt.pie(counts, labels=genres, autopct=\"%1.1f%%\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qWMMNMxU9C02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j in tags2.items():\n",
        "    if j == []:\n",
        "        print(i)\n",
        "        tags2[i] = input()"
      ],
      "metadata": {
        "id": "JHTepiXk-05T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('artist_tags.txt', 'w') as convert_file:\n",
        "     convert_file.write(json.dumps(artist_tags))"
      ],
      "metadata": {
        "id": "tacFdinnqpQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('artist_tags.txt', 'r') as convert_file:\n",
        "     artist_tags = ast.literal_eval(convert_file.read())"
      ],
      "metadata": {
        "id": "GzvTIwcp3enG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Year"
      ],
      "metadata": {
        "id": "FTwbhcCw8gj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# just getting genre by genre of artist, not release (because release definitely has some issues)\n",
        "arid = {}\n",
        "ardate = {}\n",
        "count = {}\n",
        "for c, i in enumerate(artists['Artist']):\n",
        "    i = i.strip()\n",
        "    if c%40 == 0:\n",
        "        print(\"Got\", c, \"artists\")\n",
        "    try:\n",
        "        response = requests.get(\"https://musicbrainz.org/ws/2/artist/?fmt=json&query=name:\" + urllib.parse.quote(i))\n",
        "        arid[i] = response.json()['artists'][0]['id']\n",
        "        # store the date in the thing\n",
        "        response = requests.get(\"https://musicbrainz.org/ws/2/release-group/?fmt=json&query=arid:\" + arid[i])\n",
        "        frd = int(response.json()['release-groups'][0]['first-release-date'][0:4])\n",
        "        for ii in response.json()['release-groups']:\n",
        "            try:\n",
        "                t = ii['first-release-date']\n",
        "                if int(t[0:4]) < frd:\n",
        "                    frd = int(t[0:4])\n",
        "            except:\n",
        "                continue\n",
        "        ardate[i] = frd\n",
        "    except:\n",
        "        pass"
      ],
      "metadata": {
        "id": "IslM3ZPG8iQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = {}\n",
        "for i in history['Artist']:\n",
        "    i = i.strip()\n",
        "    if i not in ardate.keys():\n",
        "        continue\n",
        "    if ardate[i] in count.keys():\n",
        "        count[ardate[i]] += 1\n",
        "    else:\n",
        "        count[ardate[i]] = 1"
      ],
      "metadata": {
        "id": "vpGBeXMbJbfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(count.keys(), count.values())"
      ],
      "metadata": {
        "id": "-f15bXYzCzGi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}