{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YTMWrapped.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOEN1ZftKu5ZwnixWo9MAOc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charlietharas/ytmusic_wrapped/blob/python3/YTMWrapped.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import sys\n",
        "import getopt\n",
        "import json\n",
        "import requests\n",
        "import re\n",
        "import pandas as pd\n",
        "import collections\n",
        "import os\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import pytz\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ge083-6rStL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Loader():\n",
        "    # backbone methods\n",
        "    def __init__(self, duration, more_details, use_songs, analyze_year, apikey, filepath):\n",
        "        self.duration, self.more_details, self.use_songs, self.analyze_year, self.apikey, self.filepath = (duration, more_details, use_songs, analyze_year, apikey, filepath)\n",
        "        self.file = self.open_file(self.filepath, \".json\")\n",
        "        \n",
        "    # utility methods\n",
        "    def should_not_ignore(self, title, year, header):\n",
        "        if (header == \"YouTube Music\" and title[:7] == \"Watched\" and year[:4] == str(self.analyze_year)):\n",
        "            return True\n",
        "        return False\n",
        "    \n",
        "    def open_file(self, filepath, filetype):\n",
        "        if (filepath.endswith(filetype)):\n",
        "            try:\n",
        "                file = open(filepath, \"r\", encoding=\"utf8\")\n",
        "                return file\n",
        "            except:\n",
        "                print(\"Could not open your report file\")\n",
        "                sys.exit()\n",
        "        else:\n",
        "            print(\"There was an error opening your report files.\")\n",
        "            sys.exit()\n",
        "            \n",
        "    \n",
        "    # processes bulk lists\n",
        "    def parse_json(self):\n",
        "        self.history = {\"Title\": [], \"Artist\": [], \"Year\": [], \"URL\": [], \"Duration\": []}\n",
        "        json_object = json.load(self.file)\n",
        "        for obj in json_object:\n",
        "            if (self.should_not_ignore(obj['title'], obj['time'], obj['header'])):\n",
        "                if ('subtitles' in obj):\n",
        "                    self.history[\"Title\"].append(obj['title'][8:])\n",
        "                    self.history[\"Artist\"].append(obj['subtitles'][0]['name'].replace('- Topic ', '').replace('- Topic', ''))\n",
        "                    self.history[\"Year\"].append(obj['time'])\n",
        "                    self.history[\"URL\"].append(obj['titleUrl'][32:])\n",
        "                    self.history[\"Duration\"].append(0)\n",
        "                    \n",
        "        occurrences = collections.Counter(self.history['URL'])\n",
        "        self.history['Occurrences'] = []\n",
        "        for i in self.history['URL']:\n",
        "            self.history['Occurrences'].append(occurrences[i])\n",
        "                    \n",
        "        occurrences = collections.Counter(self.history['Artist'])\n",
        "        duration = [0]*len(occurrences.keys())\n",
        "        self.artists = {\"Artist\": occurrences.keys(), \"Occurrences\": occurrences.values(), \"Duration\": duration}\n",
        "    \n",
        "    # generates dataframes and csv files\n",
        "    def gen_csvs(self):\n",
        "        self.historyDF = pd.DataFrame(self.history)\n",
        "        self.historyDF.to_csv(\"report-history.csv\")\n",
        "        \n",
        "        self.artistsDF = pd.DataFrame(self.artists)\n",
        "        self.artistsDF.to_csv(\"report-artists.csv\")\n",
        "        \n",
        "        self.songsDF = pd.DataFrame(self.history)\n",
        "        self.total_songs = len(self.songsDF)\n",
        "        # TODO more comprehensive duplicate dropping function (much further down the line)\n",
        "        self.songsDF.drop_duplicates(subset=['URL'], inplace=True)\n",
        "        self.unique_songs = len(self.songsDF)\n",
        "        self.songsDF = self.songsDF.reset_index(drop=True)\n",
        "        self.songsDF.to_csv(\"report-songs.csv\")\n",
        "    \n",
        "    # API management functions\n",
        "    def parse_duration(self, duration):\n",
        "        timestr = duration\n",
        "        time = re.findall(r'\\d+', timestr)\n",
        "        length = len(time)\n",
        "        if length > 4:\n",
        "            return 0\n",
        "        if length == 4:\n",
        "            return ((int(time[0])*24*60*60)+(int(time[1])*60*60)+int(time[2]*60)+(int(time[3])))\n",
        "        elif length == 3:\n",
        "            return ((int(time[0])*60*60)+(int(time[1])*60)+(int(time[2])))\n",
        "        elif length == 2:\n",
        "            return ((int(time[0])*60)+(int(time[1])))\n",
        "        elif length == 1:\n",
        "            return (int(time[0]))\n",
        "        else:\n",
        "            return 0\n",
        "    \n",
        "    def call_api(self, idlist):\n",
        "        parameters = {\"part\": \"contentDetails,snippet\",\n",
        "                      \"id\": ','.join(idlist), \"key\": self.apikey}\n",
        "        response = requests.get(\n",
        "            \"https://www.googleapis.com/youtube/v3/videos\", params=parameters)\n",
        "        \n",
        "        if (response.status_code == 200):\n",
        "            json_parsed = response.json()\n",
        "            for item in json_parsed['items']:\n",
        "                duration = self.parse_duration(item['contentDetails']['duration'])\n",
        "                url = item['id']\n",
        "                if duration < 10:\n",
        "                    duration = duration * 60\n",
        "                \n",
        "                # update by url\n",
        "                for (j, i) in enumerate(self.history[\"URL\"]):\n",
        "                    if i == url:\n",
        "                        if duration >= 10:\n",
        "                            self.history[\"Duration\"][j] = duration\n",
        "    \n",
        "    def get_duration(self):\n",
        "        # Count duration\n",
        "        idlist = []\n",
        "        calls = 0\n",
        "        unique_song_urls = set(self.history['URL'])\n",
        "        print(\"Getting durations. This may take a while. Awaiting\", len(unique_song_urls), \"requests.\")\n",
        "        for url in unique_song_urls:\n",
        "            idlist.append(url)\n",
        "            if len(idlist) == 50:\n",
        "                print(\"\\tGetting info on videos \" +\n",
        "                      str(1+50*calls) + \" - \" + str(50+50*calls))\n",
        "                self.call_api(idlist)\n",
        "                calls += 1\n",
        "                idlist = []\n",
        "        print(\"\\tGetting info on videos \" +\n",
        "              str(1+50*calls) + \" - \" + str(len(unique_song_urls)))\n",
        "        self.call_api(idlist)\n",
        "        \n",
        "        # update artist durations\n",
        "        # i know this section is garbage i'll make it nicer later\n",
        "        artist_durations = {}\n",
        "        for i in range(len(self.history[\"Artist\"])):\n",
        "            duration = self.history[\"Duration\"][i]\n",
        "            artist = self.history[\"Artist\"][i]\n",
        "            try:\n",
        "                artist_durations[artist] += duration\n",
        "            except:\n",
        "                artist_durations[artist] = duration\n",
        "                \n",
        "        occurrences = collections.Counter(self.history[\"Artist\"])\n",
        "        artists_dict = collections.defaultdict(list)\n",
        "        for i in (artist_durations, occurrences):\n",
        "            for key, val in i.items():\n",
        "                artists_dict[key].append(val)\n",
        "                \n",
        "        durations = []\n",
        "        occurrences = []\n",
        "        for i, j in artists_dict.values():\n",
        "            durations.append(i)\n",
        "            occurrences.append(j)\n",
        "            \n",
        "        self.artists = {\"Artist\": artists_dict.keys(), \"Occurrences\": occurrences, \"Duration\": durations}\n",
        "        \n",
        "        self.gen_csvs()\n",
        "        \n",
        "    def outs(self):\n",
        "        print(\"We are now processing your file\")\n",
        "        self.parse_json()            \n",
        "\n",
        "        if self.duration:\n",
        "            self.get_duration()\n",
        "        else:\n",
        "            self.gen_csvs() # generates dataframes and CSVs\n",
        "        \n",
        "        return self.historyDF, self.artistsDF, self.songsDF\n",
        "    \n",
        "    def load(self, loadfp):\n",
        "        print(\"Loading your preprocessed history files\")\n",
        "        historyDF = pd.read_csv(self.open_file(os.path.join(loadfp, \"report-history.csv\"), \".csv\"))\n",
        "        artistsDF = pd.read_csv(self.open_file(os.path.join(loadfp, \"report-artists.csv\"), \".csv\"))\n",
        "        songsDF = pd.read_csv(self.open_file(os.path.join(loadfp, \"report-songs.csv\"), \".csv\"))\n",
        "        return historyDF, artistsDF, songsDF"
      ],
      "metadata": {
        "id": "_MN-ZLgfjMBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vyqw36-9So1d"
      },
      "outputs": [],
      "source": [
        "class Analyzer():\n",
        "    def __init__(self, historyDF, artistsDF, songsDF):\n",
        "        self.history = historyDF\n",
        "        self.artists = artistsDF\n",
        "        self.songs = songsDF\n",
        "\n",
        "    def tops(self):\n",
        "        # Top 10 Songs\n",
        "        songs_top = self.songs.nlargest(10, ['Occurrences'])\n",
        "        \n",
        "        # Top 10 Artists\n",
        "        artists_top = self.artists.nlargest(10, ['Duration'])\n",
        "        \n",
        "        return artists_top, songs_top\n",
        "    \n",
        "    def meta(self):\n",
        "        meta = {}\n",
        "        meta[\"Total Seconds\"] = sum(self.history[\"Duration\"])\n",
        "        meta[\"Total Songs\"] = len(self.history[\"Title\"])\n",
        "        meta[\"Unique Songs\"] = len(self.songs[\"Title\"])\n",
        "        meta[\"Unique Artists\"] = len(self.artists[\"Artist\"])\n",
        "        return meta\n",
        "    \n",
        "    # specific optional analysis functions\n",
        "    def uniques(self):\n",
        "        uniques = {}\n",
        "        uniques[\"Top 10 Unique Artists\"] = collections.Counter(self.songs[\"Artist\"]).most_common(10)\n",
        "        return uniques\n",
        "    \n",
        "    def repeats(self):\n",
        "        repeats = {}\n",
        "        grouped_history = [(_, sum(1 for ii in i)) for _,i in itertools.groupby(self.history[\"URL\"])]\n",
        "        grouped_history.sort(key = lambda x : x[1])\n",
        "        grouped_history.reverse()\n",
        "        repeats[\"Most Consecutively Repeated Song\"] = grouped_history[:10]\n",
        "        return repeats\n",
        "    \n",
        "    def chronology(self):\n",
        "        # this stuff will break if you are analyzing a period longer than a year\n",
        "        chronology = {}\n",
        "        top_songs_per_month = []\n",
        "        for month in range(12):\n",
        "            songs_for_month = {\"Title\": [], \"Artist\": [], \"URL\": [], \"Duration\": []}\n",
        "            for j,i in enumerate(self.history[\"Year\"]):\n",
        "                if int(i[5:7]) == month+1:\n",
        "                    songs_for_month[\"Title\"].append(self.history[\"Title\"][j])\n",
        "                    songs_for_month[\"Artist\"].append(self.history[\"Artist\"][j])\n",
        "                    songs_for_month[\"URL\"].append(self.history[\"URL\"][j])\n",
        "                    songs_for_month[\"Duration\"].append(self.history[\"Duration\"][j])\n",
        "        \n",
        "            occurrences = collections.Counter(songs_for_month['URL'])\n",
        "            songs_for_month['Occurrences'] = []\n",
        "            for i in songs_for_month['URL']:\n",
        "                songs_for_month['Occurrences'].append(occurrences[i])\n",
        "            songs_for_month_DF = pd.DataFrame(songs_for_month)\n",
        "            songs_for_month_DF.drop_duplicates(subset=['URL'], inplace=True)\n",
        "            top_songs_per_month.append(songs_for_month_DF.nlargest(3, ['Occurrences']))\n",
        "\n",
        "        chronology[\"Top 3 Songs Per Month\"] = top_songs_per_month\n",
        "        \n",
        "        # TODO top dailies\n",
        "        prev_day = -1\n",
        "        count = 0\n",
        "        days = []\n",
        "        songs_for_day = {\"Title\": [], \"Artist\": [], \"URL\": [], \"Duration\": []}\n",
        "        for j, i in enumerate(self.history[\"Year\"]):\n",
        "            if i[5:10] != prev_day:\n",
        "                prev_day = i[5:10]\n",
        "                days.append(songs_for_day)\n",
        "                songs_for_day = {\"Title\": [], \"Artist\": [], \"URL\": [], \"Duration\": []}\n",
        "            songs_for_day[\"Title\"].append(self.history[\"Title\"][j])\n",
        "            songs_for_day[\"Artist\"].append(self.history[\"Artist\"][j])\n",
        "            songs_for_day[\"URL\"].append(self.history[\"URL\"][j])\n",
        "            songs_for_day[\"Duration\"].append(self.history[\"Duration\"][j])\n",
        "        days.append(songs_for_day)\n",
        "                \n",
        "        # todo most repeated song on day\n",
        "        # in the case that user doesn't really have this metric, it needs to be omitted\n",
        "        # calculating whether or not they do can be done by getting most repeated song per day, getting z-score of max of this set || i'll get to it ... later\n",
        "        \n",
        "        del days[0]\n",
        "        day_most_listened = -1 # day you listened to the most music function\n",
        "        durations_per_day = [] # durations per day function\n",
        "        songs_listened_dml = -1\n",
        "        for j, i in enumerate(days):\n",
        "            urls = collections.Counter(i[\"URL\"])\n",
        "            if ((len(urls.values())) > songs_listened_dml):\n",
        "                day_most_listened = j\n",
        "                songs_listened_dml = len(urls.values())      \n",
        "            durations_per_day.append(sum(i[\"Duration\"]))\n",
        "            \n",
        "        # since it counts from NOW to the past, this is in reverse order (this breaks of day 1 of the dataset isn't jan 1... uh oh)\n",
        "        chronology[\"Most Diverse Day\"] = [len(days) - day_most_listened , durations_per_day[day_most_listened]//60, songs_listened_dml] # this is the Nth day of the year\n",
        "        chronology[\"Durations Per Day\"] = durations_per_day\n",
        "        chronology[\"Most Musical Day\"] = [len(days) - durations_per_day.index(max(durations_per_day)), max(durations_per_day)//60] # maybe several days ?? later ig\n",
        "\n",
        "        times = {}\n",
        "        localtime = pytz.timezone(\"US/Eastern\")\n",
        "        hrs = [i for i in range(0, 24)]\n",
        "        errs = 0\n",
        "        for i in self.history[\"Year\"]:\n",
        "            try:\n",
        "                isDST = bool(localtime.localize(datetime.datetime.strptime(i[:-5], \"%Y-%m-%dT%H:%M:%S\")).dst())\n",
        "                x = int(i[11:13])\n",
        "                if isDST:\n",
        "                    x += 1\n",
        "                x -= 5\n",
        "                x = hrs[x]\n",
        "                try:\n",
        "                    times[x] += 1\n",
        "                except:\n",
        "                    times[x] = 1\n",
        "            except:\n",
        "                errs += 1\n",
        "\n",
        "        chronology[\"Songs Per Time of Day\"] = times\n",
        "        chronology[\"Songs Per Time of Day Errors\"] = errs\n",
        "\n",
        "        weekdays = {}\n",
        "        errs = 0\n",
        "        for i in self.history[\"Year\"]:\n",
        "            try:\n",
        "                wd = datetime.datetime.strptime(i[:-5], \"%Y-%m-%dT%H:%M:%S\").weekday()\n",
        "                try:\n",
        "                    weekdays[wd] += 1\n",
        "                except:\n",
        "                    weekdays[wd] = 1\n",
        "            except:\n",
        "                errs += 1\n",
        "\n",
        "        chronology[\"Days of the Week\"] = weekdays\n",
        "        chronology[\"Days of the Week Errors\"] = errs\n",
        "\n",
        "        months = {}\n",
        "        for i in self.history[\"Year\"]:\n",
        "            try:\n",
        "                months[int(i[5:7])] += 1\n",
        "            except:\n",
        "                months[int(i[5:7])] = 1\n",
        "\n",
        "        chronology[\"Songs Per Month\"] = months\n",
        "        \n",
        "        # debug \n",
        "        # print(max(durations_per_day)) # ?\n",
        "                \n",
        "        return chronology\n",
        "    \n",
        "    def averages(self):\n",
        "        averages = {}\n",
        "        averages[\"Average Song Length\"] = sum(self.history[\"Duration\"]) / len(self.history[\"Duration\"])\n",
        "        averages[\"Average Song Length Unique\"] = sum(self.songs[\"Duration\"]) / len(self.songs[\"Duration\"])\n",
        "        years = []\n",
        "        for i in self.history[\"Year\"]:\n",
        "            years.append(i[5:10])\n",
        "        averages[\"Average Seconds per Day\"] = sum(self.history[\"Duration\"]) / len(collections.Counter(years))\n",
        "        \n",
        "        min_song_length = min(self.songs[\"Duration\"])\n",
        "        max_song_length = max(self.songs[\"Duration\"])\n",
        "        min_song_idx = list(self.songs[\"Duration\"]).index(min_song_length)\n",
        "        max_song_idx = list(self.songs[\"Duration\"]).index(max_song_length)\n",
        "        \n",
        "        averages[\"Shortest Song\"] = [min_song_length, self.songs[\"Title\"][min_song_idx], self.songs[\"Artist\"][min_song_idx]]\n",
        "        averages[\"Longest Song\"] = [max_song_idx, self.songs[\"Title\"][max_song_idx], self.songs[\"Artist\"][max_song_idx]]\n",
        "        \n",
        "        # 5th percentile song by duration?\n",
        "        # 95th percentile song by duration?\n",
        "        # median song length\n",
        "        \n",
        "        history_duration_sorted = self.history[\"Duration\"].copy()\n",
        "        songs_duration_sorted = self.songs[\"Duration\"].copy()\n",
        "        history_duration_sorted = list(history_duration_sorted)\n",
        "        songs_duration_sorted = list(songs_duration_sorted)\n",
        "        history_duration_sorted.sort()\n",
        "        songs_duration_sorted.sort()\n",
        "        averages[\"Median Song Length\"] = history_duration_sorted[int(len(history_duration_sorted)/2)]\n",
        "        averages[\"Median Song Length Unique\"] = songs_duration_sorted[int(len(songs_duration_sorted)/2)]\n",
        "        \n",
        "        #plt.hist(list(self.songs[\"Duration\"]), 30, (0, 600))\n",
        "        #plt.show()\n",
        "        \n",
        "        averages[\"Average Replays\"] = sum(self.songs[\"Occurrences\"]) / len(self.songs[\"Occurrences\"])\n",
        "        averages[\"Max Replays\"] = max(self.songs[\"Occurrences\"]) # yes this statistic is already calculated somewhere else\n",
        "\n",
        "        frqtable = collections.Counter(self.songs[\"Occurrences\"])\n",
        "\n",
        "        averages[\"Occurrences Frequency Table\"] = frqtable\n",
        "        \n",
        "        return averages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Formatter():\n",
        "    def gen_report(self, args, meta, artists_top, songs_top):\n",
        "        \n",
        "        analyze_year, duration, more_details = args\n",
        "        total_seconds = meta[\"Total Seconds\"]\n",
        "        \n",
        "        # TODO rewrite HTML report generation        \n",
        "        # TODO Calculate total duration\n",
        "        htmlreport = open('report.html', 'w', encoding=(\"utf8\"))\n",
        "        print(\"\"\"<!DOCTYPE html><html><head><title>Wrapped</title><style type=\"text/css\">body{background-color: #000000;}.center-div{position: absolute; margin: auto; top: 0; right: 0; bottom: 0; left: 0; width: 50%; height: 90%; background-color: #000000; border-radius: 3px; padding: 10px;}.ytm_logo{width: 15%;position: relative;top: 30px;left: 40px;}.title_logo{width: 30%;position: relative;top: 30px;left: 60px;}.right_title{position: absolute;font-family: \"Product Sans\";top: 55px;right: 10%;font-size: 2em;color: #ffffff;}.container{position: relative;top: 13%;left: 53px;}.minutes_title{font-family: \"Product Sans\";font-size: 2em;color: #ffffff;}.minutes{font-family: \"Product Sans\";font-size: 6em;color: #ffffff;}.row{display: flex;}.column{flex: 50%;}.list{font-family: \"Roboto\";font-size: 1.5em;line-height: 30px;color: #ffffff;}</style></head><body><div class=\"center-div\"><img src=\"ytm_logo.png\" class=\"ytm_logo\"><img src=\"title.png\" class=\"title_logo\"/><span class=\"right_title\">\"\"\", file=htmlreport)\n",
        "        print(str(analyze_year), file=htmlreport)\n",
        "        print(\"\"\" Wrapped</span><div class=\"container\"><div class=\"minutes_title\">Minutes Listened</div><div class=\"minutes\">\"\"\", file=htmlreport)\n",
        "        if duration:\n",
        "            print(str(total_seconds//60), file=htmlreport)\n",
        "        else:\n",
        "            print(\"N/A\", file=htmlreport)\n",
        "        print(\"\"\"</div><br><br><div class=\"row\"><div class=\"column\"><div class=\"minutes_title\">Top Artists</div><div class=\"list\">\"\"\", file=htmlreport)\n",
        "\n",
        "        for i, j, v in zip(artists_top[\"Artist\"], artists_top[\"Occurrences\"], artists_top[\"Duration\"]): # TODO add durations to artist stuff\n",
        "            print(\"<br>\", file=htmlreport)\n",
        "            if more_details:\n",
        "                if duration:\n",
        "                    print('{0} - {1} songs ({2} mins)'.format(str(i), j, str(v//60)), file=htmlreport) # TODO v should be artist duration (?)\n",
        "                    pass\n",
        "                else:\n",
        "                    print('{0} - {1} songs'.format(str(i), j), file=htmlreport)\n",
        "            else:\n",
        "                print('{0}'.format(i), file=htmlreport)\n",
        "        print(\"\"\"</div></div><div class=\"column\"><div class=\"minutes_title\">Top Songs</div><div class=\"list\">\"\"\", file=htmlreport)\n",
        "        top_songs, top_artists, top_occurrences = songs_top['Title'], songs_top['Artist'], songs_top['Occurrences']\n",
        "        for i, j, k in zip(top_songs, top_artists, top_occurrences):\n",
        "            print(\"<br>\", file=htmlreport)\n",
        "            if more_details:\n",
        "                print('{0} - {1} - {2} plays'.format(j, i, k), file=htmlreport)\n",
        "            else:\n",
        "                print('{0} - {1}'.format(j, i), file=htmlreport)\n",
        "        print(\"\"\"</div></div></div></div></div></body></html>\"\"\", file=htmlreport)\n",
        "        htmlreport.close()"
      ],
      "metadata": {
        "id": "MzmkvU7QjQjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"drive/My Drive/Colab Notebooks/ytmwrapped\")"
      ],
      "metadata": {
        "id": "f_G-o8b3Q839"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# flags\n",
        "# TODO fix parameter/flags system\n",
        "more_details, duration, analyze_year, use_songs, apikey, load, loadfp = (True, True, True, 2021, None, True, os.getcwd())\n",
        "token = open(\"apitoken.txt\", \"r\").read()\n",
        "apikey = token\n",
        "                \n",
        "# filepath = sys.argv[1]\n",
        "filepath = \"history/watch-history.json\"\n",
        "loader = Loader(duration, more_details, analyze_year, use_songs, apikey, filepath)\n",
        "if load:\n",
        "    history, artists, songs = loader.load(loadfp)\n",
        "else:\n",
        "    history, artists, songs = loader.outs()\n",
        "\n",
        "analyzer = Analyzer(history, artists, songs)\n",
        "artists_top, songs_top = analyzer.tops()\n",
        "meta = analyzer.meta()\n",
        "\n",
        "formatter = Formatter() \n",
        "formatter.gen_report((analyze_year, duration, more_details), meta, artists_top, songs_top)\n",
        "\n",
        "print(\" -- ANALYSIS DEBUGGING -- \")\n",
        "print(\" - Meta - \")\n",
        "print(analyzer.meta())\n",
        "print(\" - Uniques - \")\n",
        "print(analyzer.uniques())\n",
        "print(\" - Repeats - \")\n",
        "print(analyzer.repeats())\n",
        "print(\" - Chronology - \")\n",
        "chrono = analyzer.chronology()\n",
        "for j, i in enumerate(chrono[\"Top 3 Songs Per Month\"]):\n",
        "    #print(j)\n",
        "    #print(i)\n",
        "    pass\n",
        "print(list(chrono.items())[1])\n",
        "print(list(chrono.items())[3])\n",
        "print(\" - Averages - \")\n",
        "averages = analyzer.averages()\n",
        "print(averages)\n",
        "\n",
        "print(\"All done!\")"
      ],
      "metadata": {
        "id": "HffdIbELSzka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "times = chrono[\"Songs Per Time of Day\"]\n",
        "x = sorted(times.keys())\n",
        "y = []\n",
        "for i in x:\n",
        "    y.append(times[i])\n",
        "\n",
        "x = list(reversed(x))\n",
        "y = list(reversed(y))\n",
        "\n",
        "def rightRotate(lists, num):\n",
        "    output_list = []\n",
        " \n",
        "    # Will add values from n to the new list\n",
        "    for item in range(len(lists) - num, len(lists)):\n",
        "        output_list.append(lists[item])\n",
        " \n",
        "    # Will add the values before\n",
        "    # n to the end of new list\n",
        "    for item in range(0, len(lists) - num):\n",
        "        output_list.append(lists[item])\n",
        " \n",
        "    return output_list\n",
        "\n",
        "x = rightRotate(x, 6)\n",
        "y = rightRotate(y, 6)"
      ],
      "metadata": {
        "id": "uO0pQ4tHbBUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the figure\n",
        "plt.figure(figsize=(20,10))\n",
        "ax = plt.subplot(111, polar=True)\n",
        "plt.axis('off')\n",
        "\n",
        "# Set the coordinates limits\n",
        "upperLimit = max(y)\n",
        "lowerLimit = min(y)\n",
        "\n",
        "# Compute max and min in the dataset\n",
        "maxval = max(y)\n",
        "\n",
        "# Let's compute heights: they are a conversion of each item value in those new coordinates\n",
        "# In our example, 0 in the dataset will be converted to the lowerLimit (10)\n",
        "# The maximum will be converted to the upperLimit (100)\n",
        "slope = (maxval - lowerLimit) / maxval\n",
        "heights = [slope * i + lowerLimit for i in y]\n",
        "\n",
        "# Compute the width of each bar. In total we have 2*Pi = 360°\n",
        "width = 2*np.pi / 24\n",
        "\n",
        "# Compute the angle each bar is centered on:\n",
        "indexes = list(range(1, 25))\n",
        "angles = [element * width for element in indexes]\n",
        "\n",
        "grey_heights = [slope*maxval + lowerLimit] * 24\n",
        "\n",
        "# Draw bars\n",
        "bars = ax.bar(\n",
        "    x=angles, \n",
        "    height=grey_heights, \n",
        "    width=width, \n",
        "    bottom=lowerLimit,\n",
        "    linewidth=2, \n",
        "    edgecolor=\"white\",\n",
        "    color=\"#d3d3d3\",\n",
        ")\n",
        "\n",
        "bars = ax.bar(\n",
        "    x=angles, \n",
        "    height=heights, \n",
        "    width=width, \n",
        "    bottom=lowerLimit,\n",
        "    linewidth=2, \n",
        "    edgecolor=\"white\",\n",
        "    color=\"#61a4b2\",\n",
        ")\n",
        "\n",
        "# little space between the bar and the label\n",
        "labelPadding = 5\n",
        "\n",
        "# Add labels\n",
        "for bar, angle, height, label in zip(bars,angles, heights, [str(i) for i in x]):\n",
        "\n",
        "    # Labels are rotated. Rotation must be specified in degrees :(\n",
        "    rotation = np.rad2deg(angle)\n",
        "\n",
        "    # Flip some labels upside down\n",
        "    alignment = \"\"\n",
        "    if angle >= np.pi/2 and angle < 3*np.pi/2:\n",
        "        alignment = \"right\"\n",
        "        rotation = rotation + 180\n",
        "    else: \n",
        "        alignment = \"left\"\n",
        "\n",
        "    # Finally add the labels\n",
        "    if (height > 100):\n",
        "        ax.text(\n",
        "            x=angle, \n",
        "            y=lowerLimit + height + labelPadding, \n",
        "            s=label, \n",
        "            ha=alignment, \n",
        "            va='center', \n",
        "            rotation=rotation, \n",
        "            rotation_mode=\"anchor\") "
      ],
      "metadata": {
        "id": "Ad--FGUdjKg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weekdays = [\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\"]\n",
        "plt.bar(weekdays, chrono[\"Days of the Week\"].values())\n",
        "print(chrono[\"Days of the Week Errors\"])"
      ],
      "metadata": {
        "id": "r69b6bzJiWZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(chrono[\"Songs Per Month\"].keys(), chrono[\"Songs Per Month\"].values())"
      ],
      "metadata": {
        "id": "LSV6CxSFmKm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(averages[\"Occurrences Frequency Table\"].keys(), averages[\"Occurrences Frequency Table\"].values())"
      ],
      "metadata": {
        "id": "w8RIC_pshSy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(averages[\"Occurrences Frequency Table\"].keys(), [i*j for i, j in zip(averages[\"Occurrences Frequency Table\"].values(), averages[\"Occurrences Frequency Table\"].keys())])"
      ],
      "metadata": {
        "id": "BKw48IU9hvWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "yF52K6t1SNH6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}